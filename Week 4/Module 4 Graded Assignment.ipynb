{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5074b9d54a7c4c8dae2324b8cb78e503",
     "grade": false,
     "grade_id": "cell-fc0b22c123cbdd06",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Module 4 Assignment\n",
    "\n",
    "In this assignment, you'll use some of the key concepts from the module to create a neural network for image classification of items of clothing. Step one will be to normalize the input images, and you'll use NDArray operations to calculate the channel mean. You'll create a function to evaluate the performance of networks on the data, and construct a couple of different neural networks for image classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f2bccf9794a4c9efd92100928a3f022e",
     "grade": false,
     "grade_id": "cell-abb560c26ec49a12",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 0) Setup\n",
    "\n",
    "We start with a number of required imports and set the data paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e397a0e3a9f2b4ad956a4b67efb70529",
     "grade": false,
     "grade_id": "cell-f6bddc494c867188",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import mxnet as mx\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "from mxnet.gluon.data.vision import FashionMNIST\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "340f681667b511ce348ad946ab4617c9",
     "grade": false,
     "grade_id": "cell-5f7e8a74007e1017",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "M4_DATA = Path(os.getenv('DATA_DIR', '../../data'), 'module_4')\n",
    "M4_IMAGES = Path(M4_DATA, 'images')\n",
    "M4_MODELS = Path(M4_DATA, 'models')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "bb710ee3e61851413d0efa8fa50e44b5",
     "grade": false,
     "grade_id": "cell-95f0a503b6239c30",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 1) Data (& NDArray Operations)\n",
    "\n",
    "We'll use the in-built dataset called `FashionMNIST` which is a variant of the commonly used `MNIST` dataset. It consists of 60,000 training images and 10,000 test images, and each image is a 28px by 28px greyscale image. We'll start by creating the `dataset` and visualize an example image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "1ed040aeb4a6597a4b1b6732e5ea1758",
     "grade": false,
     "grade_id": "cell-ddb747acaf729e37",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "test_dataset = FashionMNIST(train=False, root=M4_IMAGES).transform_first(transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3634e9be48>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sample_idx = 123\n",
    "sample_data, sample_label = test_dataset[sample_idx]\n",
    "plt.imshow(sample_data[0].asnumpy())  # 0 for first and only channel (since greyscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ed2ca106a69f67ee2e77786e0a54f4c8",
     "grade": false,
     "grade_id": "cell-cdac79c9b0e7354e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "One important step before passing images to the network is normalization: i.e. shifting and scaling the pixel values so that they are zero-centered on average and have unit variance.\n",
    "\n",
    "One method of normalization is pixelwise, where each **pixel** should have a unit normal distribution of values. Another is channelwise, where each **channel** should have a unit normal distribution of values. \n",
    "\n",
    "One of the first steps in the pixelwise approach is to calculate an 'average image' from the dataset. Using a sample of 1024 images, you should now implement a function to calculate the average intensity for every pixel. You'd typically want to calculate this from all samples of the dataset, but 1024 samples will be sufficient for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1024, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "test_dataloader = mx.gluon.data.DataLoader(test_dataset, shuffle=False, batch_size=1024)\n",
    "for data, label in test_dataloader:\n",
    "    break\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "028925a530e2ed4d602226963e5e3409",
     "grade": false,
     "grade_id": "cell-c347c7c9342cbeb1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_average_image_from_batch(batch):\n",
    "    \"\"\"\n",
    "    Given a batch of images, this function should calculate the 'average image'.\n",
    "    \n",
    "    :param batch: batch of images in NCHW layout.\n",
    "    :type batch: mx.nd.NDArray\n",
    "    \n",
    "    :return: average image in CHW layout.\n",
    "    :rtype: mx.nd.NDArray\n",
    "    \"\"\"\n",
    "    return( mx.nd.mean(batch, axis=0)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7afa5949415bf47373e5760b8df699c3",
     "grade": true,
     "grade_id": "cell-1b3d8700f95a0e26",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3634dc6c88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "average_image = get_average_image_from_batch(data)\n",
    "assert average_image.shape == (1, 28, 28)\n",
    "plt.imshow(average_image[0].asnumpy())  # 0 for first and only channel (since greyscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "1c60c3d88653d4d13ddfc97a891d2041",
     "grade": false,
     "grade_id": "cell-8289081a2395a032",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using the average image that was calculated above, you should now implement a function to perform the pixelwise normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "237357a2b5ce96f61e37e68a000aae79",
     "grade": false,
     "grade_id": "cell-970eddb5f76be1f0",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def subtract_average_image(sample, average_image):\n",
    "    \"\"\"\n",
    "    Given a sample images, this function should return a pixelwise normalized image,\n",
    "    using a pre-calculated average image.\n",
    "    \n",
    "    :param sample: sample image in CHW layout.\n",
    "    :type sample: mx.nd.NDArray\n",
    "    :param average_image: average image of the dataset in CHW layout.\n",
    "    :type average_image: mx.nd.NDArray\n",
    "    \n",
    "    :return: pixelwise normalized image in CHW layout.\n",
    "    :rtype: mx.nd.NDArray\n",
    "    \"\"\"\n",
    "    return sample-average_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "93a9e45c83be15ffd405137234e41c24",
     "grade": true,
     "grade_id": "cell-4f8cfd20e9027638",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3634d3c630>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "normalized_sample_data = subtract_average_image(sample_data, average_image)\n",
    "assert normalized_sample_data.shape == (1, 28, 28)\n",
    "np.testing.assert_array_almost_equal(normalized_sample_data.asnumpy(), (sample_data - average_image).asnumpy())\n",
    "plt.imshow(normalized_sample_data[0].asnumpy())  # 0 for first and only channel (since greyscale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've now created a transform for pixelwise normalization! As mentioned previously, another common method for normalization is channelwise normalization. Complete the following function to calculate the channel averages from a batch of multi-channel inputs.\n",
    "\n",
    "Note: although the image from our dataset only have one channel, your function should support cases where there are more than one channel (e.g. RGB images).\n",
    "\n",
    "**Hint**: Check out the `axis` (or `dim`) arguments on MXNet NDArray functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a20aa5394fbb2a4d50af68667ed995c6",
     "grade": false,
     "grade_id": "cell-d2bd82c63c0c28c9",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_channel_average_from_batch(batch):\n",
    "    \"\"\"\n",
    "    Given a batch of images, this function should return the\n",
    "    average value for each channel across the images of the batch.\n",
    "    \n",
    "    :param batch: batch of images in NCHW layout.\n",
    "    :type batch: mx.nd.NDArray\n",
    "    \n",
    "    :return: channel averages in C layout.\n",
    "    :rtype: mx.nd.NDArray\n",
    "    \"\"\"\n",
    "    return( mx.nd.mean(batch, axis=1, exclude=True)   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "61ce9104b23fdb0b51a498914c9375b3",
     "grade": true,
     "grade_id": "cell-1132428ff435fdff",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28757906\n"
     ]
    }
   ],
   "source": [
    "channel_average = get_channel_average_from_batch(data).asscalar()\n",
    "print(channel_average)\n",
    "assert isinstance(channel_average, np.float32)\n",
    "np.testing.assert_almost_equal(channel_average, 0.28757906, decimal=5)\n",
    "\n",
    "test_averages = mx.nd.array([1,2,3,4])\n",
    "test_input = mx.nd.reshape(test_averages, shape=(1,4,1,1)) * mx.nd.ones(shape=(10,4,25,25))\n",
    "test_channel_average = get_channel_average_from_batch(test_input)\n",
    "np.testing.assert_array_almost_equal(test_averages.asnumpy(), test_channel_average.asnumpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "ebf52b1649339c3bc81609fd7d8eb8a6",
     "grade": false,
     "grade_id": "cell-2fea1fe63abd02d1",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Using this channel average, we can use the `Normalize` transform to apply this to all samples in our dataset as they are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c8c7678fffe3316b1d26df20948d9d3",
     "grade": false,
     "grade_id": "cell-1406cf76c0bf2d9c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "channel_std = 0.31\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(channel_average, channel_std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "997486e117bb21d91c6c6d2e1793d5e1",
     "grade": false,
     "grade_id": "cell-09b598f5df48310e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = FashionMNIST(train=True, root=M4_IMAGES).transform_first(transform)\n",
    "test_dataset = FashionMNIST(train=False, root=M4_IMAGES).transform_first(transform)\n",
    "train_dataloader = mx.gluon.data.DataLoader(train_dataset, shuffle=True, batch_size=128)\n",
    "test_dataloader = mx.gluon.data.DataLoader(train_dataset, shuffle=False, batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Metrics\n",
    "\n",
    "In this section, you'll implement a function to test the prediction quality of networks. Using `Accuracy` as the evaluation metric, complete the following function that takes a network and a dataloader (with test data) and returns an MXNet Metric that has been updated with labels and predictions. We'll use this function in the next section, when we train classification networks.\n",
    "\n",
    "**Hint**: You'll find classes in the `mxnet.metric` subpackage useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "648cf62a617935ea6d929c14af92eb8b",
     "grade": false,
     "grade_id": "cell-5fab64bc4b4aa8dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import metric\n",
    "def calculate_accuracy(network, dataloader):\n",
    "    \"\"\"\n",
    "    Calculates accuracy of the network on the data given by the dataloader.\n",
    "    \n",
    "    :param network: network to be tested\n",
    "    :type network: mx.gluon.Block\n",
    "    :param dataloader: dataloader for test data\n",
    "    :type dataloader: mx.gluon.data.DataLoader\n",
    "    \n",
    "    :return: updated metric\n",
    "    :rtype: mx.metric.EvalMetric\n",
    "    \"\"\"\n",
    "    accuracy = metric.Accuracy()\n",
    "    for data, labels in tqdm(dataloader):\n",
    "        preds = network(data)\n",
    "        accuracy.update(labels = labels,preds = preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2a5f1bac4bcf9a3e81d52ea269a61070",
     "grade": true,
     "grade_id": "cell-56296ecc0573751e",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:46<00:00,  9.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.08005)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_network = mx.gluon.nn.Dense(units=10)\n",
    "test_network.initialize()\n",
    "metric = calculate_accuracy(test_network, test_dataloader)\n",
    "print(metric.get())\n",
    "isinstance(metric, mx.metric.EvalMetric)\n",
    "assert metric.name == 'accuracy'\n",
    "assert metric.num_inst == 60000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "cb82044f0fc5c506b7e0ded91ed9b428",
     "grade": false,
     "grade_id": "cell-3f04789a1e05233e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## 3) Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the section, you'll implement a couple of different image classification networks and train then on the `FashionMNIST` dataset. A `train` function is already provided in this assignment, because the focus will be on network construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "77f5bee4daf2e646e8b00a4cb792c9ab",
     "grade": false,
     "grade_id": "cell-027a252196f10f5c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def train(network, dataloader):\n",
    "    softmax_cross_entropy = mx.gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "    trainer = mx.gluon.Trainer(network.collect_params(), 'sgd', {'learning_rate': 0.1})\n",
    "    for data, label in tqdm(dataloader):\n",
    "        with mx.autograd.record():\n",
    "            output = network(data)\n",
    "            loss = softmax_cross_entropy(output, label)\n",
    "        loss.backward()\n",
    "        trainer.step(data.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "3d078ccad213eb7f0540c0e0a7f4fd6f",
     "grade": false,
     "grade_id": "cell-8835b94cce73c05b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Your first model should be a sequential network, with 3 layers. You first layer should have 16 hidden units, the second should have 8 hidden units and the last layer should the correct number of output units for the classification task at hand. You should add ReLU activations on all hidden layers, but not the output layer. You should define `network` in the cell below.\n",
    "\n",
    "**Hint**: You'll find classes in the `mxnet.gluon.nn` subpackage useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d35d987cac115ee0c6fcde1ccf9395ab",
     "grade": false,
     "grade_id": "cell-60d2aed0c10748dc",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from mxnet.gluon import nn\n",
    "network = nn.Sequential()\n",
    "network.add(\n",
    "    nn.Dense(16, activation='relu'),\n",
    "    nn.Dense(8, activation='relu'),\n",
    "    nn.Dense(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "bac44090ed660601c9bb11488e4457e8",
     "grade": true,
     "grade_id": "cell-fab27ff9cbdb32f3",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(network, mx.gluon.nn.Sequential)\n",
    "assert len(network) == 3\n",
    "assert isinstance(network[0], mx.gluon.nn.Dense)\n",
    "assert network[0].act.name.endswith('relu')\n",
    "assert network[0].weight.shape[0] == 16\n",
    "assert isinstance(network[1], mx.gluon.nn.Dense)\n",
    "assert network[1].act.name.endswith('relu')\n",
    "assert network[1].weight.shape[0] == 8\n",
    "assert isinstance(network[2], mx.gluon.nn.Dense)\n",
    "assert network[2].act is None\n",
    "assert network[2].weight.shape[0] == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "a12fc8925d662b2379c9da051c6ad04d",
     "grade": false,
     "grade_id": "cell-0c105c466260d8df",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "With your network now defined, you should initialize its parameters using the Xavier method in the cell below.\n",
    "\n",
    "**Hint**: You'll find classes in the `mxnet.init` subpackage useful for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "5034e223765daeb8ff11357a8385621d",
     "grade": false,
     "grade_id": "cell-fa9e3830a921ccc1",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "initializer = mx.initializer.Xavier()\n",
    "network.initialize(initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "082079014c9879392a59ea4f9ba69b89",
     "grade": true,
     "grade_id": "cell-aab6f8ac1595ddf3",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(initializer, mx.initializer.Xavier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "7b66a83fe4f502980f1aa332babea54a",
     "grade": false,
     "grade_id": "cell-71470ca5057ba4e7",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We'll now check the network summary and see that the network has 12786 trainable parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "59aea017252d590b7e5f1d59e4997cf6",
     "grade": false,
     "grade_id": "cell-a13e4f389f395b25",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                           (1024, 1, 28, 28)               0\n",
      "        Activation-1                    <Symbol dense1_relu_fwd>               0\n",
      "        Activation-2                                  (1024, 16)               0\n",
      "             Dense-3                                  (1024, 16)           12560\n",
      "        Activation-4                    <Symbol dense2_relu_fwd>               0\n",
      "        Activation-5                                   (1024, 8)               0\n",
      "             Dense-6                                   (1024, 8)             136\n",
      "             Dense-7                                  (1024, 10)              90\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 12786\n",
      "   Trainable params: 12786\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 12786\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "network.summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No idea why, but if this block is not run before calculate block is used each time, gives a weird error\n",
    "from mxnet import metric\n",
    "def calculate_accuracy(network, dataloader):\n",
    "    \"\"\"\n",
    "    Calculates accuracy of the network on the data given by the dataloader.\n",
    "    \n",
    "    :param network: network to be tested\n",
    "    :type network: mx.gluon.Block\n",
    "    :param dataloader: dataloader for test data\n",
    "    :type dataloader: mx.gluon.data.DataLoader\n",
    "    \n",
    "    :return: updated metric\n",
    "    :rtype: mx.metric.EvalMetric\n",
    "    \"\"\"\n",
    "    accuracy = metric.Accuracy()\n",
    "    for data, labels in tqdm(dataloader):\n",
    "        preds = network(data)\n",
    "        accuracy.update(labels = labels,preds = preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "d5770042162ac6a34dfd0eb57cef562a",
     "grade": false,
     "grade_id": "cell-f23f24b41797c698",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "And use the `calculate_accuracy` function defined in the previous section to evaluate the performance of this architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "958cb52f6fea4c610ad6fb12b69c9cd6",
     "grade": false,
     "grade_id": "cell-15085d2bbec07611",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [00:53<00:00,  8.80it/s]\n",
      "100%|██████████| 469/469 [00:47<00:00, 12.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.8318333333333333)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(network, train_dataloader)\n",
    "metric = calculate_accuracy(network, test_dataloader)\n",
    "print(metric.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "aae608960225ca66817116e7e18a9247",
     "grade": false,
     "grade_id": "cell-b4bb794993da124b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You're final objective in this assignment is to try a different architecture that uses convolutional and max pooling layers. You should define another sequential network, but this time it should have 5 layers in total:\n",
    "\n",
    "1. Convolutional Layer (32 channels, 3x3 kernel and ReLU activation)\n",
    "2. Max Pooling Layer (2x2 kernel and 2x2 stride)\n",
    "3. Convolutional Layer (16 channels, 3x3 kernel and ReLU activation)\n",
    "4. Max Pooling Layer (2x2 kernel and 2x2 stride)\n",
    "5. Dense Layer (10 output units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a2da3d4d690016aa9b1fddafe7c9f4c5",
     "grade": false,
     "grade_id": "cell-27362e76af20b586",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "network = nn.Sequential()\n",
    "network.add(\n",
    "    nn.Conv2D(32, (3,3),activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    nn.Conv2D(16, (3,3),activation='relu'),\n",
    "    nn.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "    nn.Dense(10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "658f43b3f172cefd8a416f9143c0cc9a",
     "grade": true,
     "grade_id": "cell-f6d99cca56b03a4c",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "assert isinstance(network, mx.gluon.nn.Sequential)\n",
    "assert len(network) == 5\n",
    "assert isinstance(network[0], mx.gluon.nn.Conv2D)\n",
    "assert network[0].act.name.endswith('relu')\n",
    "assert network[0].weight.shape[0] == 32\n",
    "assert isinstance(network[1], mx.gluon.nn.MaxPool2D)\n",
    "assert isinstance(network[2], mx.gluon.nn.Conv2D)\n",
    "assert network[2].act.name.endswith('relu')\n",
    "assert network[2].weight.shape[0] == 16\n",
    "assert isinstance(network[3], mx.gluon.nn.MaxPool2D)\n",
    "assert isinstance(network[4], mx.gluon.nn.Dense)\n",
    "assert network[4].act is None\n",
    "assert network[4].weight.shape[0] == 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "59680071ae46fddcb37e07b965fc9dbc",
     "grade": false,
     "grade_id": "cell-7aba8aa6bd98797e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's initialize the parameters of the network, and show a summary of the network architecture.\n",
    "\n",
    "With 8954 trainable parameters, this network's got 30% fewer parameters than the previous network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "226a74a762a411b9a6ec985a7b3b4d02",
     "grade": false,
     "grade_id": "cell-5b9ad1023c066bbe",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "        Layer (type)                                Output Shape         Param #\n",
      "================================================================================\n",
      "               Input                           (1024, 1, 28, 28)               0\n",
      "        Activation-1                     <Symbol conv0_relu_fwd>               0\n",
      "        Activation-2                          (1024, 32, 26, 26)               0\n",
      "            Conv2D-3                          (1024, 32, 26, 26)             320\n",
      "         MaxPool2D-4                          (1024, 32, 13, 13)               0\n",
      "        Activation-5                     <Symbol conv1_relu_fwd>               0\n",
      "        Activation-6                          (1024, 16, 11, 11)               0\n",
      "            Conv2D-7                          (1024, 16, 11, 11)            4624\n",
      "         MaxPool2D-8                            (1024, 16, 5, 5)               0\n",
      "             Dense-9                                  (1024, 10)            4010\n",
      "================================================================================\n",
      "Parameters in forward computation graph, duplicate included\n",
      "   Total params: 8954\n",
      "   Trainable params: 8954\n",
      "   Non-trainable params: 0\n",
      "Shared params in forward computation graph: 0\n",
      "Unique parameters in model: 8954\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "network.initialize(init=initializer)\n",
    "network.summary(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No idea why, but if this block is not run before calculate block is used each time, gives a weird error\n",
    "from mxnet import metric\n",
    "def calculate_accuracy(network, dataloader):\n",
    "    \"\"\"\n",
    "    Calculates accuracy of the network on the data given by the dataloader.\n",
    "    \n",
    "    :param network: network to be tested\n",
    "    :type network: mx.gluon.Block\n",
    "    :param dataloader: dataloader for test data\n",
    "    :type dataloader: mx.gluon.data.DataLoader\n",
    "    \n",
    "    :return: updated metric\n",
    "    :rtype: mx.metric.EvalMetric\n",
    "    \"\"\"\n",
    "    accuracy = metric.Accuracy()\n",
    "    for data, labels in tqdm(dataloader):\n",
    "        preds = network(data)\n",
    "        accuracy.update(labels = labels,preds = preds)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "9c93f40630de025d96f78ca5df6f8b0a",
     "grade": false,
     "grade_id": "cell-3b2f9d639c371864",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "And finally, let's evaluate the network performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "797450f201e5b58137770b5afbcdde27",
     "grade": false,
     "grade_id": "cell-6a0bbef7dab7fc86",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 469/469 [02:12<00:00,  3.73it/s]\n",
      "100%|██████████| 469/469 [03:36<00:00,  3.42it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy', 0.8416)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(network, train_dataloader)\n",
    "metric = calculate_accuracy(network, test_dataloader)\n",
    "print(metric.get())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "daac204b6befa96b9d1ceb3883b7dffb",
     "grade": false,
     "grade_id": "cell-9a3e6f798eaeb49b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "We're only training for a single epoch here. You'd expect to get improved accuracy if training for more epochs. "
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "assignment_name": "module_4",
   "assignment_version": 2,
   "course_slug": "aws-computer-vision-gluoncv",
   "graded_item_id": "FoZrl",
   "launcher_item_id": "vcm0m"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
